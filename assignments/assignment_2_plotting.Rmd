---
title: 'Assignment 2: Data visualization'
author: "Tamas Nagy"
output: html_document
editor_options: 
  chunk_output_type: console
---

You will have to create 3 plots based on the datasets and instructions detailed below. You will find the plots themeselves in the `assignments/assignment_2_plots`. Your task is to write the code that will reproduce the plots as closely as possible.

# Skills needed to solve this assignment

-   Using R and RStudio, reading data
-   Reporting using RMarkdown
-   Using Git and Github (for submitting the task)
-   Data manipulation (e.g. dplyr, tidyr), and working with factors (forcats)
-   Data visuzlization (ggplot2)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(tidytuesdayR)
library(readr)
library(dplyr)
library(ggplot2)
library(viridis)
library(scales)
library(RColorBrewer)
```

## Task 1: Climbing expeditions

The 2020-09-22 TidyTueday datasets are about climbing expeditions. From the three datasets, use the "expeditions". Reproduce the plot below! Notice a few things:

-   Use `forcats::fct_lump()` to get the 15 most frequent peaks, and drop the "Other" category.
-   The bars are ordered by the sum of all expeditions (use `fct_reorder()`).
-   The bar colors use the viridis palette and light theme.

```{r}
expeditions = read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-22/expeditions.csv")
expeditions$peak_name <- factor(expeditions$peak_name)
expeditions$season<- factor(expeditions$season)
```

```{r}
expeditions <- expeditions %>% 
  filter(!peak_name %in% c(NA))

expeditions <- expeditions %>%
  mutate(peak_name = fct_lump(peak_name, n = 15)) %>%
  filter(peak_name!= "Other")
  
expeditions$peak_freq <- 1

expeditions %>%
  ggplot(aes(fct_reorder(peak_name, peak_freq, .fun = sum)))+ 
  geom_bar(aes(fill = season)) + 
  coord_flip() +
  labs(x="", y="Number of expeditions", title = "The 15 most popular peaks stacked by season of expedition") +
  scale_fill_viridis_d()+
  theme_light()+
  theme(legend.position = "bottom", plot.title = element_text(face = "bold")) 
```

## Task 2: PhDs awarded

The 2019-02-19 TidyTueday dataset is about phd-s awarded by year and field. There is only one dataset, it is called `phd_by_field`. Reproduce the plot below!

Notes:

-   First you have to aggregate the data to count all phd-s by broad fields.
-   To make the x axis breaks pretty, use `scales::pretty_breaks()`, to make the y axis labels comma formatted, use `scales::comma_format()`.
-   The line size is 1.2, the colors are from the brewer "Dark2" palette. The theme is set to minimal.

```{r}
phd_dataset = read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv")
phd_dataset$broad_field <- factor(phd_dataset$broad_field)
phd_dataset$year <- factor(phd_dataset$year)

phd_dataset <- phd_dataset %>% 
  filter(!n_phds %in% c(NA))

phd_dataset_2 <- phd_dataset  %>% 
  group_by(broad_field,year) %>% 
  summarize(sum_n_phds=sum(n_phds))


ggplot(phd_dataset_2, aes(x=year, y=sum_n_phds, group=broad_field, color=broad_field))+ 
       scale_x_discrete(breaks = pretty_breaks(n=6)) +
       scale_y_continuous(labels = comma_format()) +
       labs(x = "", y="", title = "Number of awarded Ph.D.-s in the US by year", color= "Broad field")+ 
       theme_minimal() +
       geom_line(aes(color=broad_field), size = 1.2) +
       scale_color_brewer(palette = "Dark2")
       #theme(panel.grid.minor.x = element_line(size = 5, linetype = 2 ))
 
```

## Task 3: Commute in the US

The 2019-11-05 TidyTueday dataset is about commuting to work in each city in the US by bike or on foot. There is only one dataset, it is called `commute`. Reproduce the plot below!

Notes:

-   First you have to aggregate the data to count all commutes by state.
-   Both axis scales are log transformed and the labels comma formatted, using `scales::comma_format()`
-   The point size is 2, . The theme is set to light.

```{r}

```
